{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSP Type:\n",
    "1, CSSP: Common Spatial Spectral Pattern\n",
    "\n",
    "2, SWCSP: Spectrally Weighted Common Spatial Patterns\n",
    "\n",
    "3, ISSPL: Iterative Spatio Spectral Patterns Learning\n",
    "\n",
    "4, FBCSP: Filter Bank Common Spatial Patterns\n",
    "\n",
    "5, SCSSP: Seperable Common Spatio-spectral patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk \n",
    "import mne\n",
    "from mne.decoding import CSP\n",
    "from mne.preprocessing import ICA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_enable =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../preproc/Physionet_ssp_ica_epo.fif ...\n",
      "    Read a total of 2 projection items:\n",
      "        EOG-eeg--0.200-0.200-PCA-01 (1 x 27) active\n",
      "        EOG-eeg--0.200-0.200-PCA-02 (1 x 27) active\n",
      "    Found the data of interest:\n",
      "        t =   -2000.00 ...    4000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 2)\n",
      "2 projection items activated\n",
      "Applying baseline correction (mode: mean)\n",
      "Dropped 2 epochs: 72, 85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<EpochsFIF |  88 events (all good), -2 - 4 sec, baseline -2 â€“ 0 sec, ~17.5 MB, data loaded,\n",
       "  'T1': 44\n",
       "  'T2': 44>,\n",
       " array([72, 85]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_file = '../preproc/Physionet_ssp_ica_epo.fif'\n",
    "epochs = mne.read_epochs(epoch_file)\n",
    "epochs = epochs.apply_baseline()\n",
    "epochs.equalize_event_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs.events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: (88, 27, 961)\n",
      "Train Size: (88, 27, 161)\n"
     ]
    }
   ],
   "source": [
    "epochs_data = epochs.get_data()\n",
    "# labels = epochs.events[epochs.events[:,-1]!=3]\n",
    "labels = epochs.events[:,-1]\n",
    "labels = labels-2\n",
    "# labels = epochs.events[:,-1]-2\n",
    "print(f\"Data Size: {epochs_data.shape}\")\n",
    "\n",
    "# train data \n",
    "epochs_train = epochs.copy().crop(tmin=1, tmax=2)\n",
    "epochs_train_data = epochs_train.get_data()\n",
    "print(f\"Train Size: {epochs_train_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task  Analysis\n",
    "if plot_enable==1:\n",
    "    task = T2\n",
    "    title = str(task)[11:11+2] +' - '+ epoch_file.split('/')[-1]\n",
    "    # task.plot_topomap();\n",
    "    # task.plot_white(); # Noise cov required\n",
    "    # task.plot_field(); # requires  surf maps\n",
    "    # task.plot_sensors();\n",
    "    # task.plot_topo();\n",
    "    # task.plot_joint(times=[0.0, 0.2, 0.3]);#,picks=['C4','C2','C6','C1','C3','C5']);\n",
    "    # task.plot_image(titles=f'{title} Image',show_names='all');\n",
    "    # task.plot(proj= True, titles = '{task} - Projs - True',spatial_colors=True);\n",
    "    # task.plot(proj= False, titles = '{task} -  Projs - False',spatial_colors=True);\n",
    "    # task.plot(proj= 'reconstruct', titles = '{task} -  Projs - reconstruct',spatial_colors=True);\n",
    "    # task.plot_topomap();\n",
    "    # task.plot(gfp= \"only\"); # population standard deviation of the signal across channels\n",
    "    ## Compare regions\n",
    "    # mne.channels.combine_channels({task}, roi_dict, method='mean')\n",
    "    ## Compare conditions\n",
    "    evoked = dict(T1 = list(epochs['T1'].iter_evoked()), T2 = list(epochs['T2'].iter_evoked()))\n",
    "    mne.viz.plot_compare_evokeds(evoked, combine='mean');\n",
    "    # task_t0 = mne.combine_evoked([task, T0], weights=[1,-1])\n",
    "    # task_t0.plot_joint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evoked data\n",
    "# T0 = epochs['T0'].average() # Shape = chan x timepnts\n",
    "T1 = epochs['T1'].average()\n",
    "T2 = epochs['T2'].average()\n",
    "print(T1.data.shape)\n",
    "print(T2.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(10, test_size = 0.2, random_state=1)\n",
    "cv_split = cv.split(epochs_train_data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "svc = SVC()\n",
    "dtc = DTC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Computing rank from data with rank='full'\n",
      "    MAG: rank 27 from info\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using LEDOIT_WOLF\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.94444444, 0.94444444, 1.        , 1.        , 1.        ,\n",
       "       0.94444444, 1.        , 1.        , 0.94444444, 1.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csp = CSP(n_components=4, reg='ledoit_wolf', log=True, transform_into= 'average_power', #  reg='ledoit_wolf', log=None, norm_trace=False, rank='full',cov_est = 'epoch')#\n",
    "            cov_est = 'concat',rank='full', norm_trace= True)\n",
    "rbf = RBFSampler(gamma=1, random_state=1)\n",
    "clf = SVC()\n",
    "pip = Pipeline([('CSP', csp),('CLF', clf)])\n",
    "scores = cross_val_score(pip, epochs_train_data, labels, cv = cv, verbose=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.977778 / Chance level: 0.500000\n"
     ]
    }
   ],
   "source": [
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_data = csp.fit_transform(epochs_train_data, labels)\n",
    "csp.plot_patterns(epochs.info, title='Patterns', size = 1);\n",
    "csp.plot_filters(epochs.info, title='Filters');\n",
    "print(csp.filters_.shape)\n",
    "print(csp.patterns_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = epochs.info['sfreq']\n",
    "w_length = int(sfreq * 0.05)   # running classifier: window length\n",
    "w_step = int(sfreq * 0.01)  # running classifier: window step size\n",
    "w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)\n",
    "\n",
    "scores_windows = []\n",
    "\n",
    "for train_idx, test_idx in cv_split:\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    X_train = csp.fit_transform(epochs_train_data[train_idx], y_train)\n",
    "    X_test = csp.transform(epochs_train_data[test_idx])\n",
    "\n",
    "    # fit classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # running classifier: test classifier on sliding window\n",
    "    score_this_window = []\n",
    "    for n in w_start:\n",
    "        X_test = csp.transform(epochs_data[test_idx][:, :, n:(n + w_length)])\n",
    "        score_this_window.append(clf.score(X_test, y_test))\n",
    "    scores_windows.append(score_this_window)\n",
    "w_times = (w_start + w_length / 2.) / sfreq + epochs.tmin\n",
    "\n",
    "plt.scatter(w_times,np.mean(scores_windows,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores_windows,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = epochs.info['sfreq']\n",
    "w_length = int(sfreq * 0.05)   # running classifier: window length\n",
    "w_step = int(sfreq * 0.01)  # running classifier: window step size\n",
    "w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)\n",
    "w_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp = CSP(n_components=6, reg='ledoit_wolf', log=None, transform_into= 'average_power', #  reg='ledoit_wolf', log=None, norm_trace=False, rank='full',cov_est = 'epoch')#\n",
    "            cov_est = 'epoch',rank='full', norm_trace= True)\n",
    "csp_data = csp.fit_transform(epochs_data , labels);\n",
    "csp_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = csp.transform(epochs_data)\n",
    "evoked.data = np.mean(srcs,axis=0)\n",
    "evoked.times = np.arange(evoked.data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked.plot_topomap(times=[0, 1, 2, 3, 4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked = epochs.average()\n",
    "evoked.data = csp.filters_.T\n",
    "evoked.times = np.arange(evoked.data.shape[0])\n",
    "evoked.plot_topomap();"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
