{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA Type:\n",
    "FASTIca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk \n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_enable =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../preproc/Physionet_raw_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2000.00 ...    4000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Applying baseline correction (mode: mean)\n",
      "Dropped 2 epochs: 72, 85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<EpochsFIF |  88 events (all good), -2 - 4 sec, baseline -2 â€“ 0 sec, ~17.5 MB, data loaded,\n",
       "  'T1': 44\n",
       "  'T2': 44>,\n",
       " array([72, 85]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_file = '../preproc/Physionet_raw_epo.fif'\n",
    "epochs = mne.read_epochs(epoch_file)\n",
    "epochs = epochs.apply_baseline()\n",
    "epochs.equalize_event_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "88 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "combining channels using \"gfp\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 640x480 with 3 Axes>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.plot_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: (88, 27, 961)\n",
      "Train Size: (88, 27, 401)\n"
     ]
    }
   ],
   "source": [
    "tmin, tmax = -0.5, 2\n",
    "epochs_data = epochs.get_data()\n",
    "# labels = epochs.events[epochs.events[:,-1]!=3]\n",
    "labels = epochs.events[:,-1]\n",
    "labels = labels-2\n",
    "# labels = epochs.events[:,-1]-2\n",
    "print(f\"Data Size: {epochs_data.shape}\")\n",
    "\n",
    "# train data \n",
    "epochs_train = epochs.copy().crop(tmin= tmin, tmax=tmax)\n",
    "epochs_train_data = epochs_train.get_data()\n",
    "print(f\"Train Size: {epochs_train_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task  Analysis\n",
    "if plot_enable==1:\n",
    "    task = T2\n",
    "    title = str(task)[11:11+2] +' - '+ epoch_file.split('/')[-1]\n",
    "    # task.plot_topomap();\n",
    "    # task.plot_white(); # Noise cov required\n",
    "    # task.plot_field(); # requires  surf maps\n",
    "    # task.plot_sensors();\n",
    "    # task.plot_topo();\n",
    "    # task.plot_joint(times=[0.0, 0.2, 0.3]);#,picks=['C4','C2','C6','C1','C3','C5']);\n",
    "    # task.plot_image(titles=f'{title} Image',show_names='all');\n",
    "    # task.plot(proj= True, titles = '{task} - Projs - True',spatial_colors=True);\n",
    "    # task.plot(proj= False, titles = '{task} -  Projs - False',spatial_colors=True);\n",
    "    # task.plot(proj= 'reconstruct', titles = '{task} -  Projs - reconstruct',spatial_colors=True);\n",
    "    # task.plot_topomap();\n",
    "    # task.plot(gfp= \"only\"); # population standard deviation of the signal across channels\n",
    "    ## Compare regions\n",
    "    # mne.channels.combine_channels({task}, roi_dict, method='mean')\n",
    "    ## Compare conditions\n",
    "    evoked = dict(T1 = list(epochs['T1'].iter_evoked()), T2 = list(epochs['T2'].iter_evoked()))\n",
    "    mne.viz.plot_compare_evokeds(evoked, combine='mean');\n",
    "    # task_t0 = mne.combine_evoked([task, T0], weights=[1,-1])\n",
    "    # task_t0.plot_joint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evoked data\n",
    "# T0 = epochs['T0'].average() # Shape = chan x timepnts\n",
    "T1 = epochs['T1'].average()\n",
    "T2 = epochs['T2'].average()\n",
    "print(T1.data.shape)\n",
    "print(T2.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from mne.preprocessing import  ICA\n",
    "\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(10, test_size = 0.2, random_state=1)\n",
    "cv_split = cv.split(epochs_train_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica1 = UnsupervisedSpatialFilter(ICA(10, max_iter=200,random_state=1), average=False)\n",
    "ica_data = ica1.fit_transform(epochs_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = UnsupervisedSpatialFilter(FastICA(10, max_iter=200, tol=0.0001, w_init=None, random_state=1), average= False)\n",
    "ica_data = ica.fit_transform(epochs_train_data)\n",
    "# source = ica.get_sources(rawfltrd) # Estimate source(Noise) given the unmixing\n",
    "# print(source.get_data().shape)\n",
    "# print(ica.get_components().shape)\n",
    "# print(ica.unmixing_matrix_.shape)\n",
    "# print(rawfltrd_ica.get_data().shape)\n",
    "info_ex = mne.create_info(10, epochs.info['sfreq'],ch_types='eeg')\n",
    "# ica_evoke = mne.EvokedArray(np.mean(ica_data, axis=0), tmin=0)\n",
    "ica_epoch = mne.EpochsArray(ica_data[1,:,:], info_ex, tmin=tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 10, 401)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.info['ch_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "svc = SVC()\n",
    "dtc = DTC()\n",
    "svc.fit(ica_data_T, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ica = UnsupervisedSpatialFilter(FastICA(27), average = False)\n",
    "rbf = RBFSampler(gamma=1, random_state=1)\n",
    "clf = SVC()\n",
    "pip = Pipeline([('ICA', ica),('CLF', clf)])\n",
    "scores = cross_val_score(pip, epochs_train_data, labels, cv = cv, verbose=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_data = ica.fit_transform(epochs_data)\n",
    "ev = mne.EvokedArray(np.mean(ica_data, axis=0),\n",
    "                     mne.create_info(27, epochs.info['sfreq'],\n",
    "                                     ch_types='eeg'))\n",
    "ev.plot(show=False, window_title=\"ica\", time_unit='s'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = epochs.info['sfreq']\n",
    "w_length = int(sfreq * 0.05)   # running classifier: window length\n",
    "w_step = int(sfreq * 0.01)  # running classifier: window step size\n",
    "w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)\n",
    "\n",
    "scores_windows = []\n",
    "\n",
    "for train_idx, test_idx in cv_split:\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    X_train = ica.fit_transform(epochs_train_data[train_idx], y_train).reshape()\n",
    "    X_test = ica.transform(epochs_train_data[test_idx])\n",
    "\n",
    "    # fit classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # running classifier: test classifier on sliding window\n",
    "    score_this_window = []\n",
    "    for n in w_start:\n",
    "        X_test = ica.transform(epochs_data[test_idx][:, :, n:(n + w_length)])\n",
    "        score_this_window.append(clf.score(X_test, y_test))\n",
    "    scores_windows.append(score_this_window)\n",
    "w_times = (w_start + w_length / 2.) / sfreq + epochs.tmin\n",
    "\n",
    "plt.scatter(w_times,np.mean(scores_windows,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = epochs.info['sfreq']\n",
    "w_length = int(sfreq * 0.05)   # running classifier: window length\n",
    "w_step = int(sfreq * 0.01)  # running classifier: window step size\n",
    "w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)\n",
    "w_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = csp.transform(epochs_data)\n",
    "evoked.data = np.mean(srcs,axis=0)\n",
    "evoked.times = np.arange(evoked.data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked.plot_topomap(times=[0, 1, 2, 3, 4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked = epochs.average()\n",
    "evoked.data = csp.filters_.T\n",
    "evoked.times = np.arange(evoked.data.shape[0])\n",
    "evoked.plot_topomap();"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
