{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib tk \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import brainflow as bf\n",
    "from scipy.signal import butter,lfilter\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import mne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Raw_P1_reoorganised2.npz'\n",
    "train = np.load(f'/media/mangaldeep/HDD2/workspace/MotionControl_MasterThesis/data/{filename}', allow_pickle=True)\n",
    "train_x = np.float64(train['arr_0'])\n",
    "event_t = train['arr_1']\n",
    "train_y = train['arr_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=16, n_times=9600\n",
      "    Range : 0 ... 9599 =      0.000 ...   119.987 secs\n",
      "Ready.\n",
      "Opening raw data file /media/mangaldeep/HDD2/workspace/MotionControl_MasterThesis/main/extraction/Physionet_ChLoc_raw.fif...\n",
      "    Range : 0 ... 19679 =      0.000 ...   122.994 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "sfreq = 80.0\n",
    "ch_names = ['Fp1','Fp2','C3', 'C4','P7', 'P8', 'O1', 'O2', 'F7', 'F8','F3', 'F4','T9','T10', 'P3', 'P4']\n",
    "ch_types = ['eeg'] * 16\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types);\n",
    "raw = mne.io.RawArray(train_x, info);\n",
    "locinfo = mne.io.read_raw_fif('/media/mangaldeep/HDD2/workspace/MotionControl_MasterThesis/main/extraction/Physionet_ChLoc_raw.fif', preload = False)\n",
    "locinfo.pick_channels(raw.ch_names)\n",
    "raw._set_channel_positions(locinfo._get_channel_positions(), locinfo.ch_names)\n",
    "# raw.plot_sensors(show_names = True);\n",
    "# locinfo.plot_sensors(show_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 144000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw._data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 25.600 (s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "scal = dict(mag=1e-12, grad=4e-11, eeg=10000000e-6)\n",
    "raw.plot(scalings = scal);\n",
    "raw.plot_psd();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 25.600 (s)\n"
     ]
    }
   ],
   "source": [
    "rawfltrd = raw.filter(5, 39, verbose= False, fir_design='firwin', skip_by_annotation='edge').copy()\n",
    "scal = dict(mag=1e-12, grad=4e-11, eeg=1000e-6)\n",
    "rawfltrd.plot(scalings = scal);\n",
    "rawfltrd.plot_psd();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=16, n_times=144000\n",
      "    Range : 0 ... 143999 =      0.000 ...  1799.987 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "def normalize(train_x):\n",
    "    for j in range(train_x.shape[0]):\n",
    "        # try:\n",
    "        #     train_x[j,:]-= np.mean(train_x[j,:])\n",
    "        #     train_x[j,:] = (train_x[j,:]/np.std(train_x[j,:]) )/3\n",
    "        # except Exception as e:\n",
    "        #     train_x[j,:] =0\n",
    "        train_x[j,:] = (train_x[j,:] - train_x[j,:].min()) / (train_x[j,:].max() - train_x[j,:].min())\n",
    "    return train_x\n",
    "\n",
    "raw_nrm = normalize(rawfltrd.get_data())\n",
    "raw_nrm = mne.io.RawArray(raw_nrm, info);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Setting baseline interval to [-1.0, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Loading data for 150 events and 561 original time points ...\n",
      "7 bad epochs dropped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "# event_t = [961*i for i in range(len(train_y))]\n",
    "event_data = np.uint16(np.column_stack((event_t, np.zeros((len(train_y,))),train_y)))\n",
    "event_marker, event_id = event_data[:,0],event_data[:,2]\n",
    "# idx = event_marker[:,-1].argsort()\n",
    "# event_marker = event_marker[idx,:]\n",
    "reject = dict(    eeg=20000000000e-6)     # unit: V (EEG channels))\n",
    "event_ids = dict({'right':0, 'left':1, 'none':2}) # Replacing the existing event ids\n",
    "# epochs1 = mne.Epochs(rawfltrd, events= event_marker, event_id= event_ids, baseline = (0,0))\n",
    "epochs = mne.Epochs(rawfltrd, events= event_data, tmin= -1, tmax= 6, event_id= event_ids,reject = None,\n",
    "        verbose= True, proj= False) ;# Baseline is default (None,0)\n",
    "x_epoch = epochs.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Annotations | 150 segments: 0 (50), 1 (50), 2 (50)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.annotations_from_events(event_data,sfreq=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 49 events and 121 original time points ...\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "49 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "combining channels using \"mean\"\n",
      "Loading data for 49 events and 121 original time points ...\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n"
     ]
    }
   ],
   "source": [
    "# scal = mne.decoding.Scaler(info=info, scalings='median', with_mean=True, with_std=False)\n",
    "# dd = scal.fit_transform(epochs.get_data(), train_y)\n",
    "# dd.shape\n",
    "clas = 'left'\n",
    "\n",
    "# epochs['right'].plot_image(combine = 'mean', title = 'right');\n",
    "epochs[clas].average().plot_image(show_names = 'all', titles = clas, picks = ch_names);\n",
    "# epochs[clas].plot_topo_image(layout=layout, title = clas);\n",
    "epochs[clas].plot_image(title = clas, combine = 'mean');\n",
    "epochs[clas].plot_psd();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[raw_nrm[1,:].max()- raw_nrm[1,:].min() for i in range(16)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Recorded Epoched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutlier(train_x):\n",
    "    for ch in range(train_x.shape[0]):\n",
    "        data = train_x[ch,:].copy()\n",
    "        d25, d75 = np.percentile(data,10), np.percentile(data,90)\n",
    "        iqr = d75 - d25\n",
    "        iqr_cut = iqr *1.5\n",
    "        low, up = d25 - iqr, d75 + iqr\n",
    "        idx = np.where(np.logical_or(data < low, data> up))\n",
    "        train_x[ch,idx] = np.median(data)\n",
    "    return train_x\n",
    "\n",
    "def bandpassFilter(train_x):\n",
    "    for j in range(16):\n",
    "        order, ripple = 5, 0.5\n",
    "        lf, hf = 1,39\n",
    "        fs = 80 # Actually 80\n",
    "        b, a = butter(order, [lf, hf], fs=fs, btype='band')\n",
    "        train_x[j,:] = lfilter(b, a, train_x[j,:])\n",
    "        # bf.DataFilter.perform_bandpass(train_x[j,:], fs, lf, hf,order, 1, ripple=ripple)\n",
    "    return train_x\n",
    "    \n",
    "def plotFFT(train_x, i):\n",
    "    # Number of samplepoints\n",
    "    y = train_x[i,:]\n",
    "    N = 80\n",
    "    # sample spacing\n",
    "    # x = np.linspace(0.0, 1, N)\n",
    "    # y = np.sin(10.0 * 2.0*np.pi*x) + 0.5*np.sin(20.0 * 2.0*np.pi*x)\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0.0, N/2, N//2)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.semilogy(xf, 2.0/N * np.abs(yf[:N//2]))\n",
    "    plt.show()\n",
    "\n",
    "def epochData(train_x):\n",
    "    ep,_,_,ts = raw_data.shape\n",
    "    arr = np.split(train_x, ep, axis = 1)\n",
    "    train_x = np.stack(arr)\n",
    "    return train_x\n",
    "\n",
    "def plotComparison(x_1shot, x_bf, x_clean, i):\n",
    "    # plt.plot(np.arange(x_1shot.shape[1]),x_1shot[i,:],np.arange(x_1shot.shape[1]),x_clean[i,:], np.arange(x_1shot.shape[1]),x_bf[i,:])\n",
    "    x = np.arange(x_1shot.shape[1])\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x, y=x_1shot[i,:],\n",
    "                        mode='lines',\n",
    "                        name='Raw'))\n",
    "    fig.add_trace(go.Scatter(x=x, y=x_bf[i,:],\n",
    "                        mode='lines+markers',\n",
    "                        name='BandPassFiltered'))\n",
    "    fig.add_trace(go.Scatter(x=x, y=x_clean[i,:],\n",
    "                        mode='lines',\n",
    "                        name='Outlier removed'))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def normalize(train_x):\n",
    "    for j in range(train_x.shape[0]):\n",
    "        # try:\n",
    "        #     train_x[j,:]-= np.mean(train_x[j,:])\n",
    "        #     train_x[j,:] = (train_x[j,:]/np.std(train_x[j,:]) )/3\n",
    "        # except Exception as e:\n",
    "        #     train_x[j,:] =0\n",
    "        train_x[j,:] = (train_x[j,:] - train_x[j,:].min()) / (train_x[j,:].max() - train_x[j,:].min())\n",
    "    return train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'P1_Trial2.npz'\n",
    "train = np.load(f'/media/mangaldeep/HDD2/workspace/MotionControl_MasterThesis/data/train/{filename}', allow_pickle=True)\n",
    "train_x = np.float64(train['arr_0'])\n",
    "raw_data = train_x.copy()\n",
    "train_y = train['arr_1']\n",
    "# pio.renderers.default = 'plotly_mimetype+notebook'\n",
    "# print(pio.renderers.default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "x_1shot = np.hstack(train_x.squeeze(1))\n",
    "x_bf = bandpassFilter(x_1shot.copy())\n",
    "x_clean = removeOutlier(x_bf.copy())\n",
    "print(x_1shot.shape)\n",
    "# [x_1shot[i,:].max() - x_1shot[i,:].min() for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nrm = normalize(x_clean.copy())\n",
    "x_nrm[[12,14],:] =0\n",
    "x_epoch = epochData(x_nrm.copy())\n",
    "x_epoch = torch.tensor(x_epoch).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nrm[12,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(x_epoch.shape[-1]),y = x_epoch[1,0,15,:]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(x_1shot.shape[1]),y = x_nrm[0,:]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFFT(x_clean.copy(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotComparison(x_1shot, x_bf,x_clean,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 16, 561)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "print(x_epoch.shape)\n",
    "print(epochs.events[:,-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from data.params import OCIParams\n",
    "datadir = \"/media/mangaldeep/HDD2/workspace/MotionControl_MasterThesis/data\"\n",
    "EXPR_NAME = 'Processed_'+filename\n",
    "\n",
    "# dCfg = OCIParams()\n",
    "x_epoch = np.expand_dims(x_epoch, axis=1)\n",
    "train_x,test_x,train_y,test_y = train_test_split(x_epoch, np.float16(epochs.events[:,-1]), test_size= 0.1,\n",
    "                                stratify= epochs.events[:,-1], random_state= 42)\n",
    "# print(channel_datas.shape)\n",
    "print(f\"saving data...\")\n",
    "# labels = labels[ACTION]*np.ones(self.TOTAL_ITERS)\n",
    "np.savez(f'{datadir}/train/{EXPR_NAME}',train_x, train_y)\n",
    "np.savez(f'{datadir}/test/{EXPR_NAME}',test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scal = dict(mag=1e-12, grad=4e-11, eeg=1000000e-6)\n",
    "raw.plot(scalings = scal);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
