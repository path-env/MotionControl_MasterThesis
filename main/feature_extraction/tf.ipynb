{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk \n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/media/mangaldeep/HDD2/workspace/MotionControl_MasterThesis')\n",
    "from main.extraction.physionet_MI import extractPhysionet\n",
    "from data import brain_atlas  as bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Setting baseline interval to [-2.0, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 15 events and 961 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "raw = extractPhysionet(runs = [3], person_id = 3)\n",
    "# raw.pick_channels(['C3','C4'])\n",
    "raw.notch_filter(60)\n",
    "raw = raw.filter(7,50,verbose = False).copy()\n",
    "\n",
    "event_data = mne.events_from_annotations(raw)\n",
    "event_marker, event_ids = event_data\n",
    "event_ids = dict({'T1':2, 'T2':3})\n",
    "epochs = mne.Epochs(raw, event_marker, event_ids, tmin=-2, tmax=4, preload = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../preproc/Physionet_trial_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2000.00 ...    4000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epoch_file = '../preproc/Physionet_trial_epo.fif'\n",
    "epochs = mne.read_epochs(epoch_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Applying baseline correction (mode: mean)\n",
      "Dropped 1 epoch: 12\n"
     ]
    }
   ],
   "source": [
    "epochs = epochs.apply_proj().copy()\n",
    "epochs = epochs.apply_baseline((-2.0,-0.2)).copy()\n",
    "epochs.equalize_event_counts()\n",
    "tmin, tmax = -0.5, 2\n",
    "epochs.crop(tmin= tmin, tmax=tmax)\n",
    "T1 = epochs['T1']\n",
    "T2 = epochs['T2']\n",
    "t1 = epochs['T1'].average()\n",
    "t2 = epochs['T2'].average()\n",
    "# c =  ['C2','C4','C6', 'C1','C3','C5']\n",
    "# mne.viz.plot_compare_evokeds([T1,-T2],picks= c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>T1: 7<br>T2: 7<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.500 – 2.000 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-2.000 – -0.200 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  14 events (all good), -0.5 - 2 sec, baseline -2 – -0.2 sec (baseline period was cropped after baseline correction), ~2.8 MB, data loaded,\n",
       " 'T1': 7\n",
       " 'T2': 7>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks=['C1', 'C2','C3', 'C4', 'C5', 'C6', 'Cz']#,'T9','T10']\n",
    "epochs['T1'].average().plot_image(titles= 'T1', show_names = 'all',picks = picks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs.plot_image();\n",
    "# epochs.plot_psd();\n",
    "# scale = dict(mag=1e-12, grad=4e-11, eeg=100e-6)\n",
    "# epochs.plot(scalings = scale);\n",
    "\n",
    "t1 = epochs['T1'].average()\n",
    "# t1.plot_joint(times = (0.19,2.47));\n",
    "\n",
    "t2 = epochs['T2'].average()\n",
    "# t2.plot_joint(times = (0.19,2.47));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = -0.5, 2\n",
    "epochs_data = epochs.get_data()\n",
    "# labels = epochs.events[epochs.events[:,-1]!=3]\n",
    "labels = epochs.events[:,-1]\n",
    "labels = labels-2\n",
    "# labels = epochs.events[:,-1]-2\n",
    "print(f\"Data Size: {epochs_data.shape}\")\n",
    "\n",
    "# train data \n",
    "epochs_train = epochs.copy().crop(tmin= tmin, tmax=tmax)\n",
    "epochs_train_data = epochs_train.get_data()\n",
    "# epochs_train_data = np.transpose(epochs_train_data, axes = (1, 2, 0)) # Sklearn data = n_sam * n_freq\n",
    "print(f\"Train Size: {epochs_train_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No projector specified for this dataset. Please consider the method self.add_proj.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "picks=['C1', 'C2','C3', 'C4', 'C5', 'C6', 'Cz']#,'T9','T10']\n",
    "t2.plot_joint(picks=picks);\n",
    "# t2.plot_image(show_names = 'all', picks = picks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import tfr_morlet\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies =  np.arange(5,30,1) #np.logspace(*np.log10([5, 30]), num=25)\n",
    "picks = [1] #baseline = (-0.5, 0.),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = tfr_morlet(T1, freqs = frequencies, n_cycles = frequencies/2, return_itc= False)\n",
    "for pick in picks:\n",
    "    # power.plot(picks=[pick],  vmin=-0.00003, vmax=0.00003, title=f'{pick}')#, mode='logratio')\n",
    "    power.plot_joint(timefreqs = [(0.19,10),(2.47,10)],mode = 'logratio', title = f'{list(T1.event_id.keys())[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = tfr_morlet(T2, freqs = frequencies, n_cycles = frequencies/2, return_itc= False)\n",
    "for pick in picks:\n",
    "    # power.plot(picks=[pick],  vmin=-0.00003, vmax=0.00003, title=f'{pick}')#, mode='logratio')\n",
    "    power.plot_joint(timefreqs = [(0.19,10),(2.47,10)],mode = 'logratio', title = f'{list(T2.event_id.keys())[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "cv = ShuffleSplit(10, test_size = 0.2, random_state=1)\n",
    "cv_split = cv.split(epochs_train_data, labels)\n",
    "pipe = Pipeline([('scatter', scat_obj), ('clf', clf)])\n",
    "scores = cross_val_score(pipe, epochs_train_data, labels, cv = cv, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
