{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk \n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/media/mangaldeep/HDD2/workspace/MotionControl_MasterThesis')\n",
    "from main.extraction.physionet_MI import extractPhysionet\n",
    "from main.extraction.bci3_IVa import extractBCI3\n",
    "from data import brain_atlas  as bm\n",
    "plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physionet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = extractPhysionet(runs = [3], person_id = 3)\n",
    "# # raw.pick_channels(['C3','C4'])\n",
    "# raw.notch_filter(60)\n",
    "# raw = raw.filter(7,50,verbose = False).copy()\n",
    "\n",
    "# event_data = mne.events_from_annotations(raw)\n",
    "# event_marker, event_ids = event_data\n",
    "# event_ids = dict({'T1':2, 'T2':3})\n",
    "# epochs = mne.Epochs(raw, event_marker, event_ids, tmin=-2, tmax=4, preload = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_file = '../preproc/Physionet_trial_epo.fif'\n",
    "# epochs = mne.read_epochs(epoch_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = epochs.apply_proj().copy()\n",
    "# epochs = epochs.apply_baseline((-2.0,-0.2)).copy()\n",
    "# epochs.equalize_event_counts()\n",
    "# tmin, tmax = -0.5, 2\n",
    "# epochs.crop(tmin= tmin, tmax=tmax)\n",
    "# picks=['C1', 'C2','C3', 'C4', 'C5', 'C6', 'Cz']#,'T9','T10']\n",
    "# epochs.pick_channels(picks)\n",
    "# T1 = epochs['T1']\n",
    "# T2 = epochs['T2']\n",
    "# t1 = epochs['T1'].average()\n",
    "# t2 = epochs['T2'].average()\n",
    "# # mne.viz.plot_compare_evokeds([T1,-T2],picks= c);\n",
    "# classes = list(event_ids.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCI3 -IVa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = extractBCI3(runs = 0, person_id = 3)\n",
    "# raw = raw.filter(7,30,verbose = False).copy()\n",
    "\n",
    "# event_data = mne.events_from_annotations(raw)\n",
    "# event_marker, event_ids = event_data\n",
    "# event_ids = dict(right = 1, foot = 3, test = 2)\n",
    "# epochs = mne.Epochs(raw, event_marker, event_ids, tmin=-0.5, tmax=1, preload = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_file = '../preproc/BCI3_ssp_ica_[3]_P3_epo.fif'\n",
    "epochs = mne.read_epochs(epoch_file)\n",
    "event_ids = epochs.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epochs.apply_proj().copy()\n",
    "epochs = epochs.apply_baseline().copy()\n",
    "epochs.equalize_event_counts()\n",
    "tmin, tmax = -0.5, 2\n",
    "# epochs.crop(tmin= tmin, tmax=tmax)\n",
    "picks=['C1', 'C2','C3', 'C4', 'C5', 'C6', 'Cz']#,'T9','T10']\n",
    "epochs.pick_channels(picks)\n",
    "T1 = epochs['right']\n",
    "T2 = epochs['foot']\n",
    "t1 = epochs['right'].average()\n",
    "t2 = epochs['foot'].average()\n",
    "classes = list(event_ids.keys())\n",
    "# mne.viz.plot_compare_evokeds([T1,-T2],picks= c);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs.plot_image();\n",
    "# epochs.plot_psd();\n",
    "# scale = dict(mag=1e-12, grad=4e-11, eeg=100e-6)\n",
    "# epochs.plot(scalings = scale);\n",
    "\n",
    "# t1.plot_joint(times = (0.19,2.47));\n",
    "\n",
    "# t2.plot_joint(times = (0.19,2.47));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_data = epochs.get_data()\n",
    "# labels = epochs.events[epochs.events[:,-1]!=3]\n",
    "labels = epochs.events[:,-1]\n",
    "labels = labels-2\n",
    "# labels = epochs.events[:,-1]-2\n",
    "print(f\"Data Size: {epochs_data.shape}\")\n",
    "\n",
    "# train data \n",
    "tmin, tmax = -0.5, 1\n",
    "epochs_train = epochs.copy().crop(tmin= tmin, tmax=tmax)\n",
    "epochs_train_data = epochs_train.get_data()\n",
    "# epochs_train_data = np.transpose(epochs_train_data, axes = (1, 2, 0)) # Sklearn data = n_sam * n_freq\n",
    "print(f\"Train Size: {epochs_train_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot == True:\n",
    "    clas = 'foot'\n",
    "    # epochs['right'].plot_image(combine = 'mean', title = 'right');\n",
    "    epochs[clas].average().plot_image(show_names = 'all', titles = clas, picks = picks);\n",
    "    epochs[clas].plot_topo_image(title = clas);\n",
    "    epochs[clas].plot_image(title = clas, combine = 'mean');\n",
    "    epochs[clas].plot_psd();\n",
    "    epochs[clas].average().plot_joint(picks=picks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import tfr_morlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies =  np.arange(5,30,1) #np.logspace(*np.log10([5, 30]), num=25)\n",
    "chpicks = [1] #baseline = (-0.5, 0.),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = tfr_morlet(epochs[classes[0]], freqs = frequencies, n_cycles = frequencies/2, return_itc= False)\n",
    "if plot == True:\n",
    "    for pick in chpicks:\n",
    "        # power.plot(picks=[pick],  vmin=-0.00003, vmax=0.00003, title=f'{pick}')#, mode='logratio')\n",
    "        # power.plot_joint(timefreqs = [(0.19,10),(2.47,10)],mode = 'logratio', title = classes[0])\n",
    "        power.plot_joint(mode = 'mean', title = classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = tfr_morlet(epochs[classes[1]], freqs = frequencies, n_cycles = frequencies/2, return_itc= False)\n",
    "if plot == True:\n",
    "    for pick in chpicks:\n",
    "        # power.plot(picks=[pick],  vmin=-0.00003, vmax=0.00003, title=f'{pick}')#, mode='logratio')\n",
    "        power.plot_joint(timefreqs = [(0.19,10),(2.47,10)],mode = 'logratio', title = classes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/f removal- Power Normalization - Average TFR\n",
    "clas = 'right'\n",
    "baset = [epochs.baseline[1] , -0.2]\n",
    "power = tfr_morlet(epochs[clas], freqs = frequencies, n_cycles = frequencies/2, return_itc= False)\n",
    "powerDB = np.zeros(power.data.shape)\n",
    "t = np.arange(np.abs(baset[1]-baset[0])*epochs.info['sfreq'], dtype = np.int64)\n",
    "for ch in range(power.data.shape[0]):\n",
    "    for f in range(power.data.shape[1]):\n",
    "        baseline = np.mean(power.data[ch,f,t])\n",
    "        activity = power.data[ch,f,:]\n",
    "        powerDB[ch,f,:] = 10*np.log10(activity/baseline)\n",
    "\n",
    "newPower = mne.time_frequency.AverageTFR(epochs.info, powerDB,epochs.times, frequencies,1).copy()\n",
    "if plot == True:\n",
    "    newPower.plot_joint(title = clas, mode = 'mean');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPower.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/f removal- Power Normalization - Epochs TFR\n",
    "def powerEPdBcalc(clas):\n",
    "    baset = [epochs.baseline[1] , -0.2]\n",
    "    power = tfr_morlet(epochs[clas], freqs = frequencies, n_cycles = frequencies/2, return_itc= False, average=False)\n",
    "    shp = power.data.shape\n",
    "    powerdB = np.zeros((shp[0],shp[2],shp[3]))\n",
    "    t = np.arange(np.abs(baset[1]-baset[0])*epochs.info['sfreq'], dtype = np.int64)\n",
    "    for ep in range(power.data.shape[0]):\n",
    "        EPpower  = np.mean(power.data[ep,:,:,:],axis=1)\n",
    "        for f in range(EPpower.shape[0]):\n",
    "            baseline = np.mean(EPpower[f,t])\n",
    "            activity = EPpower[f,:]\n",
    "            powerdB[ep,f,:] = 10*np.log10(activity/baseline)\n",
    "    return powerdB\n",
    "\n",
    "# newEPPower = tfr_morlet(epochs[clas], freqs = frequencies, n_cycles = frequencies/2, return_itc= False, average=False)\n",
    "powerEpdB = {}\n",
    "powerEpdB[classes[0]] = powerEPdBcalc(classes[0])\n",
    "powerEpdB[classes[1]] = powerEPdBcalc(classes[1])\n",
    "# newPower.plot_joint(title = clas, mode = 'mean');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.vstack((powerEpdB['right'],powerEpdB['foot']))\n",
    "train_data = train_data.reshape(train_data.shape[0],-1)\n",
    "labels = np.concatenate([-np.ones(powerEpdB[classes[0]].shape[0]),\n",
    "                     np.ones(powerEpdB[classes[1]].shape[0])])\n",
    "print(train_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# powerDB.shape #[f,t]\n",
    "# plt.figure()\n",
    "# plt.imshow(powerDB[1,:,:])\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LDA()\n",
    "cv = ShuffleSplit(10, test_size = 0.2, random_state=1)\n",
    "cv_split = cv.split(train_data, labels)\n",
    "scaler = MinMaxScaler((0,1))\n",
    "train_data = scaler.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline([('scatter', scat_obj), ('clf', clf)])\n",
    "# scores = cross_val_score(pipe, epochs_train_data, labels, cv = cv, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = epochs.info['sfreq']\n",
    "w_length = int(sfreq * 0.05)   # running classifier: window length\n",
    "w_step = int(sfreq * 0.01)  # running classifier: window step size\n",
    "w_start = np.arange(0, train_data.shape[1] - w_length, w_step)\n",
    "\n",
    "scores_windows = []\n",
    "\n",
    "for train_idx, test_idx in cv_split:\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    X_train = train_data[train_idx]\n",
    "    X_test = train_data[test_idx]\n",
    "\n",
    "    # fit classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # running classifier: test classifier on sliding window\n",
    "    score_this_window = []\n",
    "    # for n in w_start:\n",
    "    #     X_test = (train_data[test_idx]) #[:, n:(n + w_length)])\n",
    "    scores_windows.append(clf.score(X_test, y_test))\n",
    "    # scores_windows.append(score_this_window)\n",
    "w_times = (w_start + w_length / 2.) / sfreq + epochs.tmin\n",
    "np.mean(scores_windows)\n",
    "# plt.scatter(scores_windows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
