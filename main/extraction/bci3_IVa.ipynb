{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as png\n",
    "# %matplotlib inline \n",
    "#  interactable inside ide\n",
    "# %matplotlib widget\n",
    "### interactable seperate window\n",
    "%matplotlib tk \n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/media/mangaldeep/HDD2/workspace/MotionControl_MasterThesis')\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extractBCI3(person_id = [0]):\n",
    "person_id = [0]\n",
    "files = ['/media/mangaldeep/HDD3/DataSets/BCI3_Competition/data_set_IVa_aa_mat/100Hz/data_set_IVa_aa.mat',\n",
    "'/media/mangaldeep/HDD3/DataSets/BCI3_Competition/data_set_IVa_al_mat/100Hz/data_set_IVa_al.mat',\n",
    "'/media/mangaldeep/HDD3/DataSets/BCI3_Competition/data_set_IVa_av_mat/100Hz/data_set_IVa_av.mat',\n",
    "'/media/mangaldeep/HDD3/DataSets/BCI3_Competition/data_set_IVa_aw_mat/100Hz/data_set_IVa_aw.mat',\n",
    "'/media/mangaldeep/HDD3/DataSets/BCI3_Competition/data_set_IVa_ay_mat/100Hz/data_set_IVa_ay.mat',]\n",
    "\n",
    "dat = loadmat(files[1], struct_as_record=True)\n",
    "extra_ch =['AFp1', 'AFp2', 'FAF5', 'FAF1', 'FAF2', 'FAF6', 'FFC7', 'FFC5', 'FFC3', 'FFC1', 'FFC2', 'FFC4', 'FFC6', \n",
    "    'FFC8', 'CFC7', 'CFC5', 'CFC3', 'CFC1', 'CFC2', 'CFC4', 'CFC6', 'CFC8', 'CCP7', 'CCP5', 'CCP3', 'CCP1', 'CCP2',\n",
    "    'CCP4', 'CCP6', 'CCP8', 'PCP7', 'PCP5', 'PCP3', 'PCP1', 'PCP2', 'PCP4', 'PCP6', 'PCP8', 'PPO7', 'PPO5', 'PPO1',\n",
    "    'PPO2', 'PPO6', 'PPO8', 'OPO1', 'OPO2', 'OI1', 'OI2', 'I1', 'I2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = dat['nfo']['fs'][0][0][0][0]\n",
    "EEGdata   = dat['cnt'].T\n",
    "EEGdata.astype('float64')\n",
    "EEGdata = EEGdata*0.1\n",
    "nchannels, nsamples = EEGdata.shape\n",
    "\n",
    "chan_names = [s[0] for s in dat['nfo']['clab'][0][0][0]]\n",
    "\n",
    "event_onsets  = dat['mrk'][0][0][0][0]\n",
    "event_codes   = dat['mrk'][0][0][1][0]\n",
    "# event_codes = np.nan_to_num(event_codes)\n",
    "\n",
    "labels = np.zeros((1, nsamples), int)\n",
    "labels[0, event_onsets] = event_codes\n",
    "\n",
    "cl_lab = [s[0] for s in dat['mrk']['className'][0][0][0]]\n",
    "cl_lab.append('nan')\n",
    "cl1    = cl_lab[0]\n",
    "cl2    = cl_lab[1]\n",
    "\n",
    "# digitized electrode positions \n",
    "xpos = dat['nfo']['xpos']\n",
    "ypos = dat['nfo']['ypos']\n",
    "\n",
    "nclasses = len(cl_lab)\n",
    "nevents = len(event_onsets)\n",
    "\n",
    "# Print some information\n",
    "print('Shape of EEG:', EEGdata.shape)\n",
    "print('Sample rate:', sfreq)\n",
    "print('Number of channels:', nchannels)\n",
    "print('Channel names:', chan_names)\n",
    "print('Number of events:', len(event_onsets))\n",
    "print('Event codes:', np.unique(event_codes))\n",
    "print('Class labels:', cl_lab)\n",
    "print('Number of classes:', nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the trials in, each class gets an entry\n",
    "trials = {}\n",
    "\n",
    "# The time window to extract for each trial, here 0. -- 3.5 seconds\n",
    "win = np.arange(int(0*sfreq), int(3.5*sfreq))\n",
    "\n",
    "# Length of the time window\n",
    "nsamples = len(win)\n",
    "\n",
    "# Loop over the classes (right, foot)\n",
    "for cl, code in zip(cl_lab, np.unique(event_codes)):\n",
    "    \n",
    "    # Extract the onsets for the class\n",
    "    cl_onsets = event_onsets[event_codes.astype('str') == str(code)]\n",
    "    \n",
    "    # Allocate memory for the trials\n",
    "    trials[cl] = np.zeros((nchannels, nsamples, len(cl_onsets)))\n",
    "    \n",
    "    # Extract each trial\n",
    "    for i, onset in enumerate(cl_onsets):\n",
    "        trials[cl][:,:,i] = EEGdata[:, win+onset]\n",
    "        \n",
    "# the dimensionality of the data (channels x time x trials)\n",
    "print('Shape of trials[cl1]:', trials[cl1].shape)\n",
    "print('Shape of trials[cl2]:', trials[cl2].shape)\n",
    "# print('Shape of trials[00]:', trials[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_hand  = np.rollaxis(trials[cl1], 2, 0)  \n",
    "foot = np.rollaxis(trials[cl2], 2, 0) \n",
    "test = np.rollaxis(trials['nan'], 2, 0) \n",
    "data = np.concatenate([right_hand, foot, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.concatenate([-np.ones(right_hand.shape[0]),\n",
    "                     np.ones(foot.shape[0]),\n",
    "                     np.zeros(test.shape[0])])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an info structure\n",
    "info = mne.create_info(\n",
    "        ch_names = chan_names,\n",
    "        ch_types = ['eeg']*nchannels,\n",
    "        sfreq    = sfreq )  \n",
    "# info.set_montage('standard_1020')\n",
    "print('Event created :', info)\n",
    "\n",
    "\n",
    "# Electrode Locations\n",
    "xpos = dat['nfo']['xpos'][0][0]\n",
    "ypos = dat['nfo']['ypos'][0][0]\n",
    "layout_pos = np.concatenate([xpos, ypos], axis = 1)\n",
    "layout = mne.channels.generate_2d_layout(\n",
    "    xy = layout_pos,\n",
    "    ch_names=chan_names,\n",
    "    name ='EEG custom layout',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "new_name = []\n",
    "for ch in ten_twenty_montage.ch_names:\n",
    "    ch = ch.lower()\n",
    "    new_name.append(ch[0].upper() + ch[1:])\n",
    "\n",
    "ten_twenty_montage.ch_names = new_name\n",
    "\n",
    "ch_names = info['ch_names']\n",
    "new_name = []\n",
    "for ch in ch_names:\n",
    "    ch = ch.lower()\n",
    "    new_name.append(ch[0].upper() + ch[1:])\n",
    "\n",
    "# # Remove dots from channel names in raw.info['ch_names']\n",
    "# new_names = []\n",
    "# for ch_name in new_name:\n",
    "#     new_names.append(ch_name.split('.')[0])\n",
    "\n",
    "mne.rename_channels(info, dict(zip(info['ch_names'], new_name)))\n",
    "# info.set_montage(ten_twenty_montage, verbose=False, on_missing='ignore');\n",
    "# print(ten_twenty_montage.ch_names)\n",
    "# print(chan_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=118, n_times=283574\n",
      "    Range : 0 ... 283573 =      0.000 ...  2835.730 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.RawArray(EEGdata, info)\n",
    "# raw = raw.pick_channels(ch_names = ten_twenty_montage.ch_names).copy()\n",
    "# mon = mne.channels.read_dig_fif('Physionet_Chloc.fif')\n",
    "# raw.set_montage('standard_1020')\n",
    "# raw.set_montage(mon, on_missing='warn')\n",
    "scale = dict(mag=1e-12, grad=4e-11, eeg=100e-6)\n",
    "rawfltrd = raw.filter(1, 30, verbose= False, fir_design='firwin', skip_by_annotation='edge').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon = mne.channels.read_dig_fif('Physionet_Chloc.fif')\n",
    "# mon.rename_channels(dict(zip(mon.ch_names,raw.info['ch_names'])))\n",
    "# mne.rename_channels(info, dict(zip(info['ch_names'], new_name)))\n",
    "# raw.set_montage('Physionet_Chloc.fif')\n",
    "# raw.set_montage(mon, on_missing='warn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locinfo = mne.io.read_raw_fif('Physionet_ChLoc_raw.fif', preload = False)\n",
    "locinfo.pick_channels(raw.ch_names)\n",
    "locinfo.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw._set_channel_positions(locinfo._get_channel_positions(), locinfo.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_sensors(show_names = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifact Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfltrd_car = rawfltrd.copy()\n",
    "rawfltrd_car.set_eeg_reference(ref_channels='average', projection=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfltrd_ssp = rawfltrd.copy()\n",
    "eog_proj, events = mne.preprocessing.compute_proj_eog(rawfltrd_ssp, n_grad=0, n_mag=0, n_eeg=2, average=True, verbose=False, ch_name = ['Fpz','Fp1','Fp2'], reject=None) # returns EOG Proj and events of blinks\n",
    "rawfltrd_ssp.add_proj(projs=eog_proj);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawfltrd_ssp.plot(scalings = scale);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cov = mne.Covariance()\n",
    "rawfltrd_ica = rawfltrd_car.apply_proj().copy()\n",
    "ica = mne.preprocessing.ICA(n_components = 20, noise_cov= None, random_state=2, method='picard',max_iter=500)\n",
    "# Create an instance of RAW\n",
    "# rawfltrd_ica = raw.copy()\n",
    "# rawfltrd_ica.apply_proj()\n",
    "ica.fit(rawfltrd_ica);\n",
    "# n_components  = 10 then ica.exclude = [1,2]\n",
    "ica.exclude = []\n",
    "# Using EOG Channel to select ICA Components\n",
    "ica.exclude , ex_scores = ica.find_bads_eog(rawfltrd_ica, ch_name=['Fpz','Fp1','Fp2']);#,threshold=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_sources(rawfltrd_ica);\n",
    "ica.plot_scores(ex_scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfltrd_ica = ica.apply(rawfltrd_ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfltrd.plot_psd();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_ids = dict(right = -1, foot = 1, test = 0)\n",
    "eventLength = Y.shape[0]\n",
    "ev = dat['mrk']['pos'][0][0][0] #[i*sfreq*3 for i in range(eventLength)]\n",
    "\n",
    "event_marker = np.column_stack((np.array(ev,  dtype = int),\n",
    "                          np.zeros(eventLength,  dtype = int),\n",
    "                          np.array(Y,  dtype = int)))\n",
    "\n",
    "ann = mne.annotations_from_events(event_marker, sfreq, event_desc = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfltrd.set_annotations(ann)\n",
    "event_data = mne.events_from_annotations(rawfltrd)\n",
    "event_marker, event_ids = event_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawepochs = rawfltrd_ica.apply_proj().copy()\n",
    "epochs = mne.Epochs(rawepochs, event_marker, event_ids, tmax = 1.0, tmin = -0.5)\n",
    "# epochs = mne.EpochsArray(data, info, events,tmin=0.0, event_id= event_id)\n",
    "epochs.apply_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = epochs['right']\n",
    "T2 = epochs['foot']\n",
    "t1 = epochs['right'].average()\n",
    "t2 = epochs['foot'].average()\n",
    "picks=['C1', 'C2','C3', 'C4', 'C5', 'C6', 'Cz']#,'T9','T10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas = 'right'\n",
    "# epochs['right'].plot_image(combine = 'mean', title = 'right');\n",
    "epochs[clas].average().plot_image(show_names = 'all', titles = clas, picks = picks);\n",
    "epochs[clas].plot_topo_image(layout=layout, title = clas);\n",
    "epochs[clas].plot_image(title = clas, combine = 'mean');\n",
    "epochs[clas].plot_psd();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas = 'right'\n",
    "epochs[clas].average().plot_image(show_names = 'all',titles = clas, picks = picks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import tfr_morlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies =  np.arange(5,30,1) #np.logspace(*np.log10([5, 30]), num=25)\n",
    "chpick = [1] #baseline = (-0.5, 0.),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_names = 'all'\n",
    "    # power.plot(picks=[10],  vmin=-0.00003, vmax=0.00003, title=f'{pick}')#, mode='logratio')\n",
    "power.plot_joint(picks = ['C1','C3','C5'], timefreqs = [(0.19,10),(2.47,10)],mode = 'logratio', title = f'{list(T1.event_id.keys())[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas = 'foot'\n",
    "power = tfr_morlet(epochs[clas], freqs = frequencies, n_cycles = frequencies/2, return_itc= False)\n",
    "for pick in chpick:\n",
    "    # power.plot(picks=[pick],  vmin=-0.00003, vmax=0.00003, title=f'{pick}')#, mode='logratio')\n",
    "    power.plot_joint(mode = 'mean', title = clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = tfr_morlet(T2, freqs = frequencies, n_cycles = frequencies/2, return_itc= False, average = False)\n",
    "# avg = power.average()\n",
    "# power.plot_topomap();\n",
    "# power.plot(picks = ['C2','C4','C6'], mode = 'mean');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas = 'right'\n",
    "baset = [epochs.baseline[1] , -0.2]\n",
    "power = tfr_morlet(epochs[clas], freqs = frequencies, n_cycles = frequencies/2, return_itc= False)\n",
    "powerDB = np.zeros(power.data.shape)\n",
    "t = np.arange(np.abs(baset[1]-baset[0])*sfreq, dtype = np.int64)\n",
    "for ch in range(power.data.shape[0]):\n",
    "    for f in range(power.data.shape[1]):\n",
    "        baseline = np.mean(power.data[ch,f,t])\n",
    "        activity = power.data[ch,f,:]\n",
    "        powerDB[ch,f,:] = 10*np.log10(activity/baseline)\n",
    "\n",
    "newPower = mne.time_frequency.AverageTFR(epochs.info, powerDB,epochs.times, frequencies,1).copy()\n",
    "newPower.plot_joint(title = clas);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPower.pick_channels(picks).plot_joint(title = clas);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.plot_image(picks = ['C1','C3','C5','C2','C4','C6'],show_names = 'all');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1.plot_image(combine = 'mean');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.plot_topomap();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kymatio.sklearn import Scattering2D\n",
    "from kymatio.sklearn import Scattering1D\n",
    "from kymatio.scattering2d.filter_bank import filter_bank\n",
    "# from numpy.fft import fft\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# %matplotlib tk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,N = epochs.get_data().shape[1:]\n",
    "J,L = 3,8\n",
    "scat2D = Scattering2D(J=J,shape=(M,N),L=L)\n",
    "data = epochs['right','foot'].get_data()\n",
    "data = data.reshape(224,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for every epochs \n",
    "Sx = scat2D(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = epochs['right', 'foot'].get_data()\n",
    "train_data = train_data.reshape(train_data.shape[0],-1)\n",
    "labels = np.concatenate([-np.ones(right_hand.shape[0]),\n",
    "                     np.ones(foot.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LDA()\n",
    "cv = ShuffleSplit(10, test_size = 0.2, random_state=1)\n",
    "cv_split = cv.split(train_data, labels)\n",
    "pipe = Pipeline([('scatter', scat2D), ('clf', clf)])\n",
    "scores = cross_val_score(pipe, train_data, labels, cv = cv, verbose=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "cv = ShuffleSplit(10, test_size = 0.2, random_state=1)\n",
    "cv_split = cv.split(train_data, labels)\n",
    "pipe = Pipeline([('scatter', scat2D), ('clf', clf)])\n",
    "scores = cross_val_score(pipe, train_data, labels, cv = cv, verbose=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DTC()\n",
    "cv = ShuffleSplit(10, test_size = 0.2, random_state=1)\n",
    "cv_split = cv.split(train_data, labels)\n",
    "pipe = Pipeline([('scatter', scat2D), ('clf', clf)])\n",
    "scores = cross_val_score(pipe, train_data, labels, cv = cv, verbose=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(epochs['right', 'foot'].get_data(), labels)\n",
    "pipe.predict(epochs['test'][0].get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "for i in range(epochs['test'].get_data().shape[0]):\n",
    "    ans.append(pipe.predict(epochs['test'][i].get_data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['right', 'foot'].get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
